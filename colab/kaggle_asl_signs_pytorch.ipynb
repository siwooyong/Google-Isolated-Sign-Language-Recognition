{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5UmPWijX00m"
      },
      "source": [
        "# pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RhpY53mg9WH"
      },
      "source": [
        "## library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ2H9Ngby0Ob",
        "outputId": "554170e0-915f-4407-974b-80707b36a4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: onnx_tf in /usr/local/lib/python3.10/dist-packages (1.10.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from onnx_tf) (6.0)\n",
            "Requirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from onnx_tf) (1.13.1)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (from onnx_tf) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx_tf) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx_tf) (4.5.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx_tf) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons->onnx_tf) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons->onnx_tf) (2.13.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tflite-runtime (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tflite-runtime\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import gc\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import random\n",
        "import os\n",
        "import json \n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "!pip install onnx_tf\n",
        "!pip install tflite-runtime\n",
        "!pip install torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "import onnx\n",
        "import onnx_tf\n",
        "from onnx_tf.backend import prepare\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "!pip install transformers\n",
        "from transformers import BertModel, BertConfig, GPT2Model, GPT2Config, RobertaModel, RobertaConfig\n",
        "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdfa3g-qgzVw"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Suqmg0Og1bP"
      },
      "outputs": [],
      "source": [
        "def load_relevant_data_subset_with_imputation(args, pq_path):\n",
        "  data_columns = ['x', 'y', 'z']\n",
        "  data = pd.read_parquet(pq_path, columns=data_columns)\n",
        "  data.replace(np.nan, 0, inplace=True)\n",
        "  n_frames = int(len(data) / args.rows_per_frame)\n",
        "  data = data.values.reshape(n_frames, args.rows_per_frame, len(data_columns))\n",
        "  return data.astype(np.float32)\n",
        "\n",
        "def load_relevant_data_subset(args, pq_path):\n",
        "  data_columns = ['x', 'y', 'z']\n",
        "  data = pd.read_parquet(pq_path, columns=data_columns)\n",
        "  n_frames = int(len(data) / args.rows_per_frame)\n",
        "  data = data.values.reshape(n_frames, args.rows_per_frame, len(data_columns))\n",
        "  return data.astype(np.float32)\n",
        "\n",
        "def read_dict(args, file_path):\n",
        "  path = os.path.expanduser(file_path)\n",
        "  with open(path, \"r\") as f:\n",
        "    dic = json.load(f)\n",
        "  return dic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDd3XDD3g2L_"
      },
      "source": [
        "## config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx6gqkTm4UA8"
      },
      "outputs": [],
      "source": [
        "class CustomConfig():\n",
        "\n",
        "  # training\n",
        "  seed = 42\n",
        "  batch_size = 128\n",
        "  num_workers = 12\n",
        "  device = 'cuda'\n",
        "  folder = 'result'\n",
        "  lr = 1e-3\n",
        "  epoch_n = 40\n",
        "  rows_per_frame = 75\n",
        "  warmup_ratio = 0.2\n",
        "  max_frame = 100\n",
        "  data_path = \"/content/asl-signs/\"\n",
        "  smoothing = 0.2\n",
        "  fold_n = 5\n",
        "\n",
        "  # modeling\n",
        "  in_features = rows_per_frame * 3\n",
        "  out_features = 32\n",
        "  hidden_size = 64\n",
        "  dense_dim = 512\n",
        "  num_classes = 250\n",
        "  drop_rate = 0.4\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  args = CustomConfig()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PJvFRJvhkeV"
      },
      "source": [
        "## seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ScO7RV5zjf8"
      },
      "outputs": [],
      "source": [
        "def seed_everything(args):\n",
        "    random.seed(args.seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  seed_everything(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ged5z_rhlbl"
      },
      "source": [
        "## aggregate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dnsec-hlrrZt"
      },
      "outputs": [],
      "source": [
        "'''def collate_fn(batch):\n",
        "  data = [item[\"data\"] for item in batch]  \n",
        "  label = [item[\"label\"] for item in batch]  \n",
        "  frame = [item[\"frame\"] for item in batch]  \n",
        "  batch_id = [item[\"batch_id\"] for item in batch]  \n",
        "\n",
        "  return {\"data\": torch.concat(data, dim = 0), \n",
        "          \"label\": torch.concat(label, dim = 0),  \n",
        "          \"frame\": torch.concat(frame, dim = 0),\n",
        "          \"batch_id\": torch.concat(batch_id, dim = 0)}\n",
        "\n",
        "class PreprocessDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, args, df):\n",
        "    self.args = args\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    path = f\"{self.args.data_path}{self.df.iloc[idx].path}\"\n",
        "\n",
        "    data = load_relevant_data_subset(args, path)#load_relevant_data_subset_with_imputation(args, path)\n",
        "    label = self.df.iloc[idx].label\n",
        "    frame = data.shape[0]\n",
        "    batch_id = [idx] * frame\n",
        "  \n",
        "    return {'data' : torch.tensor(data, dtype = torch.float), \n",
        "            'label' : torch.tensor([label], dtype = torch.float), \n",
        "            'frame' : torch.tensor([frame], dtype = torch.float),\n",
        "            'batch_id' : torch.tensor(batch_id, dtype = torch.float)}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  dataset = PreprocessDataset(args, train)\n",
        "  dataloader = torch.utils.data.DataLoader(dataset, \n",
        "                                           batch_size = 128, \n",
        "                                           num_workers = 12, \n",
        "                                           shuffle = False, \n",
        "                                           drop_last = False, \n",
        "                                           collate_fn = collate_fn)\n",
        "\n",
        "  data, label, frame, batch_id = [], [], [], []\n",
        "  for k, sample in enumerate(tqdm(dataloader)):\n",
        "    data.append(sample['data'])\n",
        "    label.append(sample['label'])\n",
        "    frame.append(sample['frame'])\n",
        "    batch_id.append(sample['batch_id'])\n",
        "    \n",
        "\n",
        "  data = torch.concat(data, dim = 0)\n",
        "  label = torch.concat(label, dim = 0)\n",
        "  frame = torch.concat(frame, dim = 0)\n",
        "  batch_id = torch.concat(batch_id, dim = 0)'''\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqu3s1hvwbo-"
      },
      "outputs": [],
      "source": [
        "#data.shape, label.shape, frame.shape, batch_id.shape, train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umK2UICL4gJ3"
      },
      "outputs": [],
      "source": [
        "#np.save('/content/drive/MyDrive/Kaggle/aggregation/data_without_imputation.npy', data.numpy()) \n",
        "#np.save('/content/drive/MyDrive/Kaggle/aggregation/label_without_imputation.npy', label.numpy())\n",
        "#np.save('/content/drive/MyDrive/Kaggle/aggregation/frame_without_imputation.npy', frame.numpy()) \n",
        "#np.save('/content/drive/MyDrive/Kaggle/aggregation/batch_id_without_imputation.npy', batch_id.numpy()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc6f2r1Rg-Rf"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "rightEyebrowUpper: [156, 70, 63, 105, 66, 107, 55, 193],\n",
        "rightEyebrowLower: [35, 124, 46, 53, 52, 65],\n",
        "leftEyebrowUpper: [383, 300, 293, 334, 296, 336, 285, 417],\n",
        "leftEyebrowLower: [265, 353, 276, 283, 282, 295],\n",
        "\n",
        "rightEyebrow : [156, 70, 63, 105, 66, 107, 55, 193, 35, 124, 46, 53, 52, 65]\n",
        "leftEyebrow : [383, 300, 293, 334, 296, 336, 285, 417, 265, 353, 276, 283, 282, 295]\n",
        "'''\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDk8ThYYE5E7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "lipsUpperOuter: [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291],\n",
        "lipsLowerOuter: [146, 91, 181, 84, 17, 314, 405, 321, 375, 291],\n",
        "lipsUpperInner: [78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308],\n",
        "lipsLowerInner: [78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308],\n",
        "'''\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la6QbF3PyccC"
      },
      "outputs": [],
      "source": [
        "'''LIP = [\n",
        "    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
        "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
        "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
        "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308\n",
        "    ]\n",
        "\n",
        "lip = data[:, LIP, :]\n",
        "without_face = data[:, 468:, :]\n",
        "data_with_lip = np.concatenate([lip, without_face], axis = 1)\n",
        "np.save('/content/drive/MyDrive/Kaggle/aggregation/data_m_with_lip.npy', data_with_lip) '''\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzhPjmPsieM3"
      },
      "outputs": [],
      "source": [
        "'''LIP = [\n",
        "    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
        "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
        "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
        "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308\n",
        "    ]\n",
        "\n",
        "EYEBROW = [\n",
        "    156, 70, 63, 105, 66, 107, 55, 193, 35, 124, 46, 53, 52, 65, \n",
        "    383, 300, 293, 334, 296, 336, 285, 417, 265, 353, 276, 283, 282, 295\n",
        "    ]\n",
        "\n",
        "lip = data[:, LIP, :]\n",
        "without_face = data[:, 468:, :]\n",
        "eyebrow = data[:, EYEBROW, :]\n",
        "data_with_lip_and_eyebrow = np.concatenate([lip, without_face, eyebrow], axis = 1)\n",
        "np.save('/content/drive/MyDrive/Kaggle/aggregation/data_m_with_lip_and_eyebrow.npy', data_with_lip_and_eyebrow) '''\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi5hxyfIxl2l"
      },
      "outputs": [],
      "source": [
        "data = np.load('/content/drive/MyDrive/Kaggle/aggregation/data_m_with_lip.npy')#np.load('/content/drive/MyDrive/Kaggle/aggregation/data.npy')\n",
        "label = np.load('/content/drive/MyDrive/Kaggle/aggregation/label.npy')\n",
        "frame = np.load('/content/drive/MyDrive/Kaggle/aggregation/frame.npy')\n",
        "batch_id = np.load('/content/drive/MyDrive/Kaggle/aggregation/batch_id.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agUH2PT-AgD1",
        "outputId": "182b83ca-878b-4cc2-91b9-43acf504a6e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3583987, 115, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVYurNgBzS2q",
        "outputId": "88784496-ab97-4124-dad1-0a4106822636"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaGqMd6XkiRD"
      },
      "source": [
        "## preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqZT44OHzqOR"
      },
      "outputs": [],
      "source": [
        "def preprocess(args):\n",
        "  participant_ids = np.array([26734, 28656, 16069, 25571, 62590, 32319, 37055, 29302, 49445,\n",
        "                              36257, 22343, 27610, 61333, 53618, 34503, 18796,  4718, 55372,\n",
        "                              2044, 37779, 30680])\n",
        "                            \n",
        "  df = pd.read_csv('/content/drive/MyDrive/Kaggle/train.csv')#df = pd.DataFrame()\n",
        "  df['frame'] = frame\n",
        "  df['label'] = label\n",
        "  df['original_index'] = np.arange(len(df))\n",
        "  \n",
        "  kf = KFold(n_splits = args.fold_n, shuffle = False)\n",
        "\n",
        "  folds = list()\n",
        "  for train_index, test_index in kf.split(participant_ids):\n",
        "    train_ids = participant_ids[train_index]\n",
        "    test_ids = participant_ids[test_index]\n",
        "\n",
        "    train_df = df[df['participant_id'].isin(train_ids)].reset_index(drop = True)\n",
        "    test_df = df[df['participant_id'].isin(test_ids)].reset_index(drop = True)\n",
        "\n",
        "    col = ['frame', 'label', 'original_index']\n",
        "    folds.append([train_df[col], test_df[col]])\n",
        "  return folds, df[col]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  folds, df = preprocess(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUIa_uEDkjVZ"
      },
      "source": [
        "## dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIxJvttNNT0a"
      },
      "outputs": [],
      "source": [
        "# feature version2\n",
        "\n",
        "class FeatureGen(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureGen, self).__init__()\n",
        "        self.triu = torch.tensor([[0] * (bi + 1) + [1] * (20 - bi) for bi in range(21)], dtype = torch.float).unsqueeze(0)\n",
        "        self.ptriu = torch.tensor([[0] * (bi + 1) + [1] * (24 - bi) for bi in range(25)], dtype = torch.float).unsqueeze(0)\n",
        "        self.ltriu = torch.tensor([[0] * (bi + 1) + [1] * (19 - bi) for bi in range(20)], dtype = torch.float).unsqueeze(0)\n",
        "        #self.simple_pose = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
        "        pass\n",
        "    \n",
        "    def forward(self, x, mode):\n",
        "        xfeat = x[:, 0:, :][:200]\n",
        "\n",
        "        lefth_x = x[:,40:61,:]\n",
        "        righth_x = x[:,94:,:]\n",
        "        pose_x = x[:, 61:86, :]#[:, self.simple_pose]\n",
        "        lip_x = x[:, :40, :]\n",
        "\n",
        "        if (lefth_x!=0).sum() > (righth_x!=0).sum():\n",
        "            \n",
        "            lefth_x[:, :, 0] = -lefth_x[:, :, 0]\n",
        "            pose_x[:, :, 0] = -pose_x[:, :, 0]\n",
        "            lip_x[:, :, 0] = -lip_x[:, :, 0]\n",
        "            xfeat = torch.cat([lefth_x, pose_x, lip_x], dim = 1)\n",
        "            h_x = lefth_x.reshape(lefth_x.shape[0], -1)\n",
        "            hand_mask = (h_x.sum(1)!=0)\n",
        "            token_type_ids = (h_x.sum(1)!=0) + 1\n",
        "            #if indices.sum() != 0:\n",
        "            #    xfeat = xfeat[indices]\n",
        "            \n",
        "            #if mode == 'aug':\n",
        "            #  if indices.sum() > 10:\n",
        "            #      aug_indices = (torch.rand(xfeat.shape[0])>0.00).long()\n",
        "            #      xfeat = xfeat[aug_indices]\n",
        "\n",
        "            xfeat = torch.where(torch.isnan(xfeat), torch.tensor(0.0, dtype=torch.float32), xfeat)\n",
        "\n",
        "            dxyz = torch.cat([xfeat[:-1] - xfeat[1:], torch.zeros(1, xfeat.shape[1], xfeat.shape[2])], dim = 0)\n",
        "            lhand = xfeat[:, :21, :3]\n",
        "            ld = lhand.reshape(-1, 21, 1, 3) - lhand.reshape(-1, 1, 21, 3)\n",
        "            ld = torch.sqrt((ld ** 2).sum(-1)) + 1\n",
        "            ld = ld * self.triu\n",
        "            indices = (ld.reshape(ld.shape[0], -1)!=0)\n",
        "            ld = ld.reshape(ld.shape[0], -1)[indices].reshape(ld.shape[0], -1)\n",
        "            dist = ld\n",
        "            dist = dist - 1 \n",
        "            \n",
        "        \n",
        "        else:\n",
        "            xfeat = torch.cat([righth_x, pose_x, lip_x], dim = 1)\n",
        "            h_x = righth_x.reshape(righth_x.shape[0], -1)\n",
        "            hand_mask = (h_x.sum(1)!=0)\n",
        "            token_type_ids = (h_x.sum(1)!=0) + 1\n",
        "            #if indices.sum() != 0:\n",
        "            #    xfeat = xfeat[indices]\n",
        "\n",
        "            #if mode == 'aug':\n",
        "            #  if indices.sum() > 10:\n",
        "            #      aug_indices = (torch.rand(xfeat.shape[0])>0.00).long()\n",
        "            #      xfeat = xfeat[aug_indices]\n",
        "\n",
        "            xfeat = torch.where(torch.isnan(xfeat), torch.tensor(0.0, dtype=torch.float32), xfeat)\n",
        "\n",
        "            dxyz = torch.cat([xfeat[:-1] - xfeat[1:], torch.zeros(1, xfeat.shape[1], xfeat.shape[2])], dim = 0)\n",
        "            rhand = xfeat[:, :21, :3]\n",
        "            rd = rhand.reshape(-1, 21, 1, 3) - rhand.reshape(-1, 1, 21, 3)\n",
        "            rd = torch.sqrt((rd ** 2).sum(-1)) + 1\n",
        "            rd = rd * self.triu\n",
        "            indices = (rd.reshape(rd.shape[0], -1)!=0)\n",
        "            rd = rd.reshape(rd.shape[0], -1)[indices].reshape(rd.shape[0], -1)\n",
        "            dist = rd\n",
        "            dist = dist - 1\n",
        "\n",
        "        pose = xfeat[:, 21:46, :2]\n",
        "        pd = pose.reshape(-1, 25, 1, 2) - pose.reshape(-1, 1, 25, 2)\n",
        "        pd = torch.sqrt((pd ** 2).sum(-1)) + 1\n",
        "        pd = pd * self.ptriu\n",
        "        indices = (pd.reshape(pd.shape[0], -1)!=0)\n",
        "        pd = pd.reshape(pd.shape[0], -1)[indices].reshape(pd.shape[0], -1)\n",
        "        pdist = pd\n",
        "        pdist = pdist - 1\n",
        "\n",
        "        olip = xfeat[:, 46:66, :2]\n",
        "        old = olip.reshape(-1, 20, 1, 2) - olip.reshape(-1, 1, 20, 2)\n",
        "        old = torch.sqrt((old ** 2).sum(-1)) + 1\n",
        "        old = old * self.ltriu\n",
        "        indices = (old.reshape(old.shape[0], -1)!=0)\n",
        "        old = old.reshape(old.shape[0], -1)[indices].reshape(old.shape[0], -1)\n",
        "        oldist = old\n",
        "        oldist = oldist - 1\n",
        "\n",
        "        ilip = xfeat[:, 66:86, :2]\n",
        "        ild = ilip.reshape(-1, 20, 1, 2) - ilip.reshape(-1, 1, 20, 2)\n",
        "        ild = torch.sqrt((ild ** 2).sum(-1)) + 1\n",
        "        ild = ild * self.ltriu\n",
        "        indices = (ild.reshape(ild.shape[0], -1)!=0)\n",
        "        ild = ild.reshape(ild.shape[0], -1)[indices].reshape(ild.shape[0], -1)\n",
        "        ildist = ild\n",
        "        ildist = ildist - 1\n",
        "\n",
        "        xfeat = torch.cat([\n",
        "            xfeat[:, :21, :3].reshape(xfeat.shape[0], -1), \n",
        "            xfeat[:, 21:46, :2].reshape(xfeat.shape[0], -1), \n",
        "            xfeat[:, 46:66, :2].reshape(xfeat.shape[0], -1), \n",
        "            dxyz[:, :21, :3].reshape(xfeat.shape[0], -1), \n",
        "            dxyz[:, 21:46, :2].reshape(xfeat.shape[0], -1), \n",
        "            dxyz[:, 46:66, :2].reshape(xfeat.shape[0], -1), \n",
        "            dist.reshape(xfeat.shape[0], -1),\n",
        "            pdist.reshape(xfeat.shape[0], -1),\n",
        "            oldist.reshape(xfeat.shape[0], -1),\n",
        "            ildist.reshape(xfeat.shape[0], -1),\n",
        "            token_type_ids.reshape(xfeat.shape[0], -1),\n",
        "            hand_mask.reshape(xfeat.shape[0], -1)\n",
        "        ], dim = -1)\n",
        "\n",
        "        \n",
        "        return xfeat\n",
        "    \n",
        "feature_converter = FeatureGen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YW05d8zFahF4"
      },
      "outputs": [],
      "source": [
        "# feature version1\n",
        "\n",
        "class FeatureGen(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureGen, self).__init__()\n",
        "        self.triu = torch.tensor([[0] * (bi + 1) + [1] * (20 - bi) for bi in range(21)], dtype = torch.float).unsqueeze(0)\n",
        "        self.ptriu = torch.tensor([[0] * (bi + 1) + [1] * (24 - bi) for bi in range(25)], dtype = torch.float).unsqueeze(0)\n",
        "        self.ltriu = torch.tensor([[0] * (bi + 1) + [1] * (19 - bi) for bi in range(20)], dtype = torch.float).unsqueeze(0)\n",
        "        #self.simple_pose = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
        "        pass\n",
        "    \n",
        "    def forward(self, x, mode):\n",
        "        xfeat = x[:, 0:, :]\n",
        "\n",
        "        lefth_x = x[:,40:61,:]\n",
        "        righth_x = x[:,94:,:]\n",
        "        pose_x = x[:, 61:86, :]#[:, self.simple_pose]\n",
        "        lip_x = x[:, :40, :]\n",
        "\n",
        "        if (lefth_x!=0).sum() > (righth_x!=0).sum():\n",
        "            \n",
        "            lefth_x[:, :, 0] = -lefth_x[:, :, 0]\n",
        "            pose_x[:, :, 0] = -pose_x[:, :, 0]\n",
        "            lip_x[:, :, 0] = -lip_x[:, :, 0]\n",
        "            xfeat = torch.cat([lefth_x, pose_x, lip_x], dim = 1)\n",
        "            h_x = lefth_x.reshape(lefth_x.shape[0], -1)\n",
        "            indices = (h_x.sum(1)!=0)\n",
        "            if indices.sum() != 0:\n",
        "                xfeat = xfeat[indices]\n",
        "\n",
        "\n",
        "            xfeat = torch.where(torch.isnan(xfeat), torch.tensor(0.0, dtype=torch.float32), xfeat)\n",
        "\n",
        "            dxyz = torch.cat([xfeat[:-1] - xfeat[1:], torch.zeros(1, xfeat.shape[1], xfeat.shape[2])], dim = 0)\n",
        "            lhand = xfeat[:, :21, :3]\n",
        "            ld = lhand.reshape(-1, 21, 1, 3) - lhand.reshape(-1, 1, 21, 3)\n",
        "            ld = torch.sqrt((ld ** 2).sum(-1)) + 1\n",
        "            ld = ld * self.triu\n",
        "            indices = (ld.reshape(ld.shape[0], -1)!=0)\n",
        "            ld = ld.reshape(ld.shape[0], -1)[indices].reshape(ld.shape[0], -1)\n",
        "            dist = ld\n",
        "            dist = dist - 1 \n",
        "            \n",
        "        \n",
        "        else:\n",
        "            xfeat = torch.cat([righth_x, pose_x, lip_x], dim = 1)\n",
        "            h_x = righth_x.reshape(righth_x.shape[0], -1)\n",
        "            indices = (h_x.sum(1)!=0)\n",
        "            if indices.sum() != 0:\n",
        "                xfeat = xfeat[indices]\n",
        "\n",
        "\n",
        "\n",
        "            xfeat = torch.where(torch.isnan(xfeat), torch.tensor(0.0, dtype=torch.float32), xfeat)\n",
        "\n",
        "            dxyz = torch.cat([xfeat[:-1] - xfeat[1:], torch.zeros(1, xfeat.shape[1], xfeat.shape[2])], dim = 0)\n",
        "            rhand = xfeat[:, :21, :3]\n",
        "            rd = rhand.reshape(-1, 21, 1, 3) - rhand.reshape(-1, 1, 21, 3)\n",
        "            rd = torch.sqrt((rd ** 2).sum(-1)) + 1\n",
        "            rd = rd * self.triu\n",
        "            indices = (rd.reshape(rd.shape[0], -1)!=0)\n",
        "            rd = rd.reshape(rd.shape[0], -1)[indices].reshape(rd.shape[0], -1)\n",
        "            dist = rd\n",
        "            dist = dist - 1\n",
        "\n",
        "        pose = xfeat[:, 21:46, :2]\n",
        "        pd = pose.reshape(-1, 25, 1, 2) - pose.reshape(-1, 1, 25, 2)\n",
        "        pd = torch.sqrt((pd ** 2).sum(-1)) + 1\n",
        "        pd = pd * self.ptriu\n",
        "        indices = (pd.reshape(pd.shape[0], -1)!=0)\n",
        "        pd = pd.reshape(pd.shape[0], -1)[indices].reshape(pd.shape[0], -1)\n",
        "        pdist = pd\n",
        "        pdist = pdist - 1\n",
        "\n",
        "        olip = xfeat[:, 46:66, :2]\n",
        "        old = olip.reshape(-1, 20, 1, 2) - olip.reshape(-1, 1, 20, 2)\n",
        "        old = torch.sqrt((old ** 2).sum(-1)) + 1\n",
        "        old = old * self.ltriu\n",
        "        indices = (old.reshape(old.shape[0], -1)!=0)\n",
        "        old = old.reshape(old.shape[0], -1)[indices].reshape(old.shape[0], -1)\n",
        "        oldist = old\n",
        "        oldist = oldist - 1\n",
        "\n",
        "        ilip = xfeat[:, 66:86, :2]\n",
        "        ild = ilip.reshape(-1, 20, 1, 2) - ilip.reshape(-1, 1, 20, 2)\n",
        "        ild = torch.sqrt((ild ** 2).sum(-1)) + 1\n",
        "        ild = ild * self.ltriu\n",
        "        indices = (ild.reshape(ild.shape[0], -1)!=0)\n",
        "        ild = ild.reshape(ild.shape[0], -1)[indices].reshape(ild.shape[0], -1)\n",
        "        ildist = ild\n",
        "        ildist = ildist - 1\n",
        "\n",
        "        xfeat = torch.cat([\n",
        "            xfeat[:, :21, :3].reshape(xfeat.shape[0], -1), \n",
        "            xfeat[:, 21:46, :2].reshape(xfeat.shape[0], -1), \n",
        "            xfeat[:, 46:66, :2].reshape(xfeat.shape[0], -1), \n",
        "            dxyz[:, :21, :3].reshape(xfeat.shape[0], -1), \n",
        "            dxyz[:, 21:46, :2].reshape(xfeat.shape[0], -1), \n",
        "            dxyz[:, 46:66, :2].reshape(xfeat.shape[0], -1), \n",
        "            dist.reshape(xfeat.shape[0], -1),\n",
        "            pdist.reshape(xfeat.shape[0], -1),\n",
        "            oldist.reshape(xfeat.shape[0], -1),\n",
        "            ildist.reshape(xfeat.shape[0], -1),\n",
        "        ], dim = -1)\n",
        "        \n",
        "\n",
        "        \n",
        "        return xfeat\n",
        "    \n",
        "feature_converter = FeatureGen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNz6R6wDaVZX",
        "outputId": "1bd64d3c-848d-43ef-b0f9-fd0737a88cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1196])\n",
            "tensor(193)\n"
          ]
        }
      ],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, args, df, data, mode='aug'):\n",
        "    self.args = args\n",
        "    self.df = df\n",
        "    self.data = data\n",
        "    self.mode = mode\n",
        "    \n",
        "    frame = np.load('/content/drive/MyDrive/Kaggle/aggregation/frame.npy')\n",
        "    self.indices = self.cumulative_sum_tuples(frame.astype(int))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    frame, label, original_index  = self.df.iloc[idx]\n",
        "\n",
        "    start_idx, end_idx = self.indices[int(original_index)]\n",
        "    \n",
        "    x = torch.tensor(self.data[start_idx:end_idx], dtype = torch.float)\n",
        "    x = feature_converter(x, self.mode)\n",
        "    x = self.pad(x)\n",
        "    y = torch.tensor(int(label), dtype = torch.long)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "  def pad(self, x):\n",
        "    if x.shape[0] > self.args.max_frame:\n",
        "      padded_x = x[:self.args.max_frame]\n",
        "    else:\n",
        "      padded_x = torch.zeros(self.args.max_frame, x.shape[-1])\n",
        "      padded_x[:x.shape[0]] = x\n",
        "\n",
        "    return padded_x\n",
        "\n",
        "  def cumulative_sum_tuples(self, lst):\n",
        "    result = [(0, lst[0])]\n",
        "    if len(lst) > 0:\n",
        "      cum_sum = lst[0]\n",
        "      for i in range(1, len(lst)):\n",
        "        cum_sum += lst[i]\n",
        "        result.append((cum_sum-lst[i], cum_sum))\n",
        "    return result\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  train_df, val_df = folds[1]\n",
        "  dataset = CustomDataset(args, val_df, data, 'aug')\n",
        "  i = random.randint(0, len(val_df)-1)\n",
        "  sample = dataset[i]\n",
        "  print(sample[0].shape)\n",
        "  print(sample[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMSYeZwNaW5w"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6Y8PQKx3ofh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f72d758-430a-4013-a8c1-5c02d9523cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 250])\n"
          ]
        }
      ],
      "source": [
        "# model version 2, 3\n",
        "\n",
        "from transformers import RobertaPreLayerNormConfig, RobertaPreLayerNormModel\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self, args):\n",
        "    super(CustomModel, self).__init__()\n",
        "    self.args = args\n",
        "\n",
        "    self.hidden = 384\n",
        "     \n",
        "    self.xy_embeddings = nn.Linear(153, self.hidden)\n",
        "    self.motion_embeddings = nn.Linear(153, self.hidden)\n",
        "    self.dist_embeddings = nn.Linear(210, self.hidden)\n",
        "    self.pdist_embeddings = nn.Linear(300, self.hidden)\n",
        "    self.oldist_embeddings = nn.Linear(190, self.hidden)\n",
        "    self.ildist_embeddings = nn.Linear(190, self.hidden)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.content_embeddings = nn.Linear(self.hidden * 6, self.hidden)\n",
        "    \n",
        "    self.encoder = RobertaPreLayerNormModel(\n",
        "        RobertaPreLayerNormConfig(\n",
        "            hidden_size = self.hidden,\n",
        "            num_hidden_layers = 1,\n",
        "            num_attention_heads = 4,\n",
        "            intermediate_size = 1024,\n",
        "            hidden_act = 'relu',\n",
        "            type_vocab_size = 3\n",
        "            )\n",
        "        )\n",
        "    \n",
        "    self.fc = nn.Linear(self.hidden * 3, 1024)\n",
        "    self.bn = nn.BatchNorm1d(1024)\n",
        "    self.drop = nn.Dropout(0.4)\n",
        "\n",
        "    self.out = nn.Linear(1024, 250)\n",
        "    \n",
        "    torch.nn.init.xavier_uniform_(self.xy_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.motion_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.dist_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.pdist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.oldist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.ildist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.content_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.fc.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.out.weight)  \n",
        "\n",
        "  def get_att_mask(self, x):\n",
        "    att_mask = x.sum(-1)\n",
        "    att_mask = (att_mask!=0).float()\n",
        "    return att_mask\n",
        "\n",
        "  def get_pool(self, x, x_mask):\n",
        "    x = x * x_mask.unsqueeze(-1)  # apply mask\n",
        "    nonzero_count = x_mask.sum(1).unsqueeze(-1)  # count nonzero elements\n",
        "    max_discount = (1-x_mask)*1e10\n",
        "\n",
        "    apool = x.sum(1) / nonzero_count\n",
        "    mpool, _ = torch.max(x - max_discount.unsqueeze(-1), dim = 1)\n",
        "    spool = torch.sqrt((torch.sum(((x - apool.unsqueeze(1)) ** 2)*x_mask.unsqueeze(-1), dim = 1) / nonzero_count)+1e-9)\n",
        "    return torch.cat([apool, mpool, spool], dim = -1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    token_type_ids = x[:, :, -2].long()\n",
        "    hand_mask = x[:, :, -1].long()\n",
        "    x = x[:, :, :1196]\n",
        "    x_mask = self.get_att_mask(x)\n",
        "\n",
        "    xy = self.xy_embeddings(x[:, :, :153])\n",
        "    motion = self.motion_embeddings(x[:, :, 153:306])\n",
        "    dist = self.dist_embeddings(x[:, :, 306:516])\n",
        "    pdist = self.pdist_embeddings(x[:, :, 516:816])\n",
        "    oldist = self.oldist_embeddings(x[:, :, 816:1006])\n",
        "    ildist = self.ildist_embeddings(x[:, :, 1006:1196])\n",
        "\n",
        "    x = torch.cat([xy, motion, dist, pdist, oldist, ildist], dim = -1)\n",
        "    x = self.relu(x)\n",
        "    x = self.content_embeddings(x)\n",
        "    x = self.encoder(inputs_embeds = x, attention_mask = x_mask, token_type_ids = token_type_ids).last_hidden_state\n",
        "    \n",
        "    #x = self.get_pool(x, hand_mask)\n",
        "    x = self.get_pool(x, x_mask)\n",
        "\n",
        "    x = self.fc(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.drop(x)\n",
        "\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  model = CustomModel(args)\n",
        "  model.eval()\n",
        "  output = model(sample[0].unsqueeze(0))\n",
        "  print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCM7yRO9llYa",
        "outputId": "c69914ff-63b8-424c-d052-dd4a008085b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 250])\n"
          ]
        }
      ],
      "source": [
        "# model version 1\n",
        "\n",
        "from transformers import RobertaPreLayerNormConfig, RobertaPreLayerNormModel\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self, args):\n",
        "    super(CustomModel, self).__init__()\n",
        "    self.args = args\n",
        "\n",
        "    self.hidden = 384\n",
        "     \n",
        "    self.xy_embeddings = nn.Linear(153, self.hidden)\n",
        "    self.motion_embeddings = nn.Linear(153, self.hidden)\n",
        "    self.dist_embeddings = nn.Linear(210, self.hidden)\n",
        "    self.pdist_embeddings = nn.Linear(300, self.hidden)\n",
        "    self.oldist_embeddings = nn.Linear(190, self.hidden)\n",
        "    self.ildist_embeddings = nn.Linear(190, self.hidden)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.content_embeddings = nn.Linear(self.hidden * 6, self.hidden)\n",
        "    \n",
        "    self.encoder = RobertaPreLayerNormModel(\n",
        "        RobertaPreLayerNormConfig(\n",
        "            hidden_size = self.hidden,\n",
        "            num_hidden_layers = 1,\n",
        "            num_attention_heads = 4,\n",
        "            intermediate_size = 1024,\n",
        "            hidden_act = 'relu',\n",
        "            )\n",
        "        )\n",
        "    \n",
        "    self.fc1 = nn.Linear(self.hidden * 3, 1024)\n",
        "    self.bn1 = nn.BatchNorm1d(1024)\n",
        "    self.drop = nn.Dropout(0.4)\n",
        "\n",
        "    self.out = nn.Linear(1024, 250)\n",
        "    \n",
        "    torch.nn.init.xavier_uniform_(self.xy_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.motion_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.dist_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.pdist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.oldist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.ildist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.content_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.fc1.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.out.weight)  \n",
        "\n",
        "  def get_att_mask(self, x):\n",
        "    att_mask = x.sum(-1)\n",
        "    att_mask = (att_mask!=0).float()\n",
        "    return att_mask\n",
        "\n",
        "  def get_pool(self, x, x_mask):\n",
        "    x = x * x_mask.unsqueeze(-1)  # apply mask\n",
        "    nonzero_count = x_mask.sum(1).unsqueeze(-1)  # count nonzero elements\n",
        "    max_discount = (1-x_mask)*1e10\n",
        "\n",
        "    apool = x.sum(1) / nonzero_count\n",
        "    mpool, _ = torch.max(x - max_discount.unsqueeze(-1), dim = 1)\n",
        "    spool = torch.sqrt((torch.sum(((x - apool.unsqueeze(1)) ** 2)*x_mask.unsqueeze(-1), dim = 1) / nonzero_count)+1e-9)\n",
        "    return torch.cat([apool, mpool, spool], dim = -1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_mask = self.get_att_mask(x)\n",
        "\n",
        "    xy = self.xy_embeddings(x[:, :, :153])\n",
        "    motion = self.motion_embeddings(x[:, :, 153:306])\n",
        "    dist = self.dist_embeddings(x[:, :, 306:516])\n",
        "    pdist = self.pdist_embeddings(x[:, :, 516:816])\n",
        "    oldist = self.oldist_embeddings(x[:, :, 816:1006])\n",
        "    ildist = self.ildist_embeddings(x[:, :, 1006:1196])\n",
        "\n",
        "    x = torch.cat([xy, motion, dist, pdist, oldist, ildist], dim = -1)\n",
        "    x = self.relu(x)\n",
        "    x = self.content_embeddings(x)\n",
        "    x = self.encoder(inputs_embeds = x, attention_mask = x_mask).last_hidden_state\n",
        "    \n",
        "    x = self.get_pool(x, x_mask)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.drop(x)\n",
        "\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  model = CustomModel(args)\n",
        "  model.eval()\n",
        "  output = model(sample[0].unsqueeze(0))\n",
        "  print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model version 4\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self, args):\n",
        "    super(CustomModel, self).__init__()\n",
        "    self.args = args\n",
        "\n",
        "    self.hidden = 768\n",
        "     \n",
        "    self.xy_embeddings = nn.Linear(153, self.hidden)\n",
        "    self.motion_embeddings = nn.Linear(153, self.hidden)\n",
        "    self.dist_embeddings = nn.Linear(210, self.hidden)\n",
        "    self.pdist_embeddings = nn.Linear(300, self.hidden)\n",
        "    self.oldist_embeddings = nn.Linear(190, self.hidden)\n",
        "    self.ildist_embeddings = nn.Linear(190, self.hidden)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.content_embeddings = nn.Linear(self.hidden * 6, self.hidden)\n",
        "    \n",
        "    self.encoder = nn.Linear(self.hidden, self.hidden)\n",
        "    \n",
        "    self.fc1 = nn.Linear(self.hidden * 3, 1024)\n",
        "    self.bn1 = nn.BatchNorm1d(1024)\n",
        "    self.drop = nn.Dropout(0.4)\n",
        "\n",
        "    self.out = nn.Linear(1024, 250)\n",
        "    \n",
        "    torch.nn.init.xavier_uniform_(self.xy_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.motion_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.dist_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.pdist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.oldist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.ildist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.content_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.encoder.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.fc1.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.out.weight)  \n",
        "\n",
        "  def get_att_mask(self, x):\n",
        "    att_mask = x.sum(-1)\n",
        "    att_mask = (att_mask!=0).float()\n",
        "    return att_mask\n",
        "\n",
        "  def get_pool(self, x, x_mask):\n",
        "    x = x * x_mask.unsqueeze(-1)  # apply mask\n",
        "    nonzero_count = x_mask.sum(1).unsqueeze(-1)  # count nonzero elements\n",
        "    max_discount = (1-x_mask)*1e10\n",
        "\n",
        "    apool = x.sum(1) / nonzero_count\n",
        "    mpool, _ = torch.max(x - max_discount.unsqueeze(-1), dim = 1)\n",
        "    spool = torch.sqrt((torch.sum(((x - apool.unsqueeze(1)) ** 2)*x_mask.unsqueeze(-1), dim = 1) / nonzero_count)+1e-9)\n",
        "    return torch.cat([apool, mpool, spool], dim = -1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_mask = self.get_att_mask(x)\n",
        "\n",
        "    xy = self.xy_embeddings(x[:, :, :153])\n",
        "    motion = self.motion_embeddings(x[:, :, 153:306])\n",
        "    dist = self.dist_embeddings(x[:, :, 306:516])\n",
        "    pdist = self.pdist_embeddings(x[:, :, 516:816])\n",
        "    oldist = self.oldist_embeddings(x[:, :, 816:1006])\n",
        "    ildist = self.ildist_embeddings(x[:, :, 1006:1196])\n",
        "\n",
        "    x = torch.cat([xy, motion, dist, pdist, oldist, ildist], dim = -1)\n",
        "    x = self.relu(x)\n",
        "    x = self.content_embeddings(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.encoder(x)\n",
        "    \n",
        "    x = self.get_pool(x, x_mask)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.drop(x)\n",
        "\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  model = CustomModel(args)\n",
        "  model.eval()\n",
        "  output = model(sample[0].unsqueeze(0))\n",
        "  print(output.shape)"
      ],
      "metadata": {
        "id": "hV4Fk-_jGVB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5f3784-4432-4ef6-a851-24db102cd1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 250])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model version 5\n",
        "\n",
        "from transformers import RobertaPreLayerNormConfig, RobertaPreLayerNormModel\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self, args):\n",
        "    super(CustomModel, self).__init__()\n",
        "    self.args = args\n",
        "\n",
        "    self.hidden = 384\n",
        "     \n",
        "    self.xy_embeddings = nn.Linear(153, self.hidden)\n",
        "    self.motion_embeddings = nn.Linear(153, self.hidden)\n",
        "    self.dist_embeddings = nn.Linear(210, self.hidden)\n",
        "    self.pdist_embeddings = nn.Linear(300, self.hidden)\n",
        "    self.oldist_embeddings = nn.Linear(190, self.hidden)\n",
        "    self.ildist_embeddings = nn.Linear(190, self.hidden)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.content_embeddings = nn.Linear(self.hidden * 6, self.hidden)\n",
        "    \n",
        "    self.encoder = nn.GRU(self.hidden, self.hidden, batch_first = True)\n",
        "    \n",
        "    self.fc1 = nn.Linear(self.hidden * 3, 1024)\n",
        "    self.bn1 = nn.BatchNorm1d(1024)\n",
        "    self.drop = nn.Dropout(0.4)\n",
        "\n",
        "    self.out = nn.Linear(1024, 250)\n",
        "    \n",
        "    torch.nn.init.xavier_uniform_(self.xy_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.motion_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.dist_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.pdist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.oldist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.ildist_embeddings.weight) \n",
        "    torch.nn.init.xavier_uniform_(self.content_embeddings.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.fc1.weight)  \n",
        "    torch.nn.init.xavier_uniform_(self.out.weight)  \n",
        "\n",
        "  def get_att_mask(self, x):\n",
        "    att_mask = x.sum(-1)\n",
        "    att_mask = (att_mask!=0).float()\n",
        "    return att_mask\n",
        "\n",
        "  def get_pool(self, x, x_mask):\n",
        "    x = x * x_mask.unsqueeze(-1)  # apply mask\n",
        "    nonzero_count = x_mask.sum(1).unsqueeze(-1)  # count nonzero elements\n",
        "    max_discount = (1-x_mask)*1e10\n",
        "\n",
        "    apool = x.sum(1) / nonzero_count\n",
        "    mpool, _ = torch.max(x - max_discount.unsqueeze(-1), dim = 1)\n",
        "    spool = torch.sqrt((torch.sum(((x - apool.unsqueeze(1)) ** 2)*x_mask.unsqueeze(-1), dim = 1) / nonzero_count)+1e-9)\n",
        "    return torch.cat([apool, mpool, spool], dim = -1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_mask = self.get_att_mask(x)\n",
        "\n",
        "    xy = self.xy_embeddings(x[:, :, :153])\n",
        "    motion = self.motion_embeddings(x[:, :, 153:306])\n",
        "    dist = self.dist_embeddings(x[:, :, 306:516])\n",
        "    pdist = self.pdist_embeddings(x[:, :, 516:816])\n",
        "    oldist = self.oldist_embeddings(x[:, :, 816:1006])\n",
        "    ildist = self.ildist_embeddings(x[:, :, 1006:1196])\n",
        "\n",
        "    x = torch.cat([xy, motion, dist, pdist, oldist, ildist], dim = -1)\n",
        "    x = self.relu(x)\n",
        "    x = self.content_embeddings(x)\n",
        "    x, _ = self.encoder(x)\n",
        "    \n",
        "    x = self.get_pool(x, x_mask)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.drop(x)\n",
        "\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  model = CustomModel(args)\n",
        "  model.eval()\n",
        "  output = model(sample[0].unsqueeze(0))\n",
        "  print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lysyUwbq5FEX",
        "outputId": "82ec34b7-88d5-4537-a732-4b0cca6fbc6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 250])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wui0LgnpBE3A"
      },
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnZ5spduGP_Q"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "from copy import deepcopy\n",
        "from collections import OrderedDict\n",
        "\n",
        "_logger = logging.getLogger(__name__)\n",
        "\n",
        "class ModelEma:\n",
        "    \"\"\" Model Exponential Moving Average (DEPRECATED)\n",
        "    Keep a moving average of everything in the model state_dict (parameters and buffers).\n",
        "    This version is deprecated, it does not work with scripted models. Will be removed eventually.\n",
        "    This is intended to allow functionality like\n",
        "    https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
        "    A smoothed version of the weights is necessary for some training schemes to perform well.\n",
        "    E.g. Google's hyper-params for training MNASNet, MobileNet-V3, EfficientNet, etc that use\n",
        "    RMSprop with a short 2.4-3 epoch decay period and slow LR decay rate of .96-.99 requires EMA\n",
        "    smoothing of weights to match results. Pay attention to the decay constant you are using\n",
        "    relative to your update count per epoch.\n",
        "    To keep EMA from using GPU resources, set device='cpu'. This will save a bit of memory but\n",
        "    disable validation of the EMA weights. Validation will have to be done manually in a separate\n",
        "    process, or after the training stops converging.\n",
        "    This class is sensitive where it is initialized in the sequence of model init,\n",
        "    GPU assignment and distributed training wrappers.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, decay=0.9999, device='', resume=''):\n",
        "        # make a copy of the model for accumulating moving average of weights\n",
        "        self.ema = deepcopy(model)\n",
        "        self.ema.eval()\n",
        "        self.decay = decay\n",
        "        self.device = device  # perform ema on different device from model if set\n",
        "        if device:\n",
        "            self.ema.to(device=device)\n",
        "        self.ema_has_module = hasattr(self.ema, 'module')\n",
        "        if resume:\n",
        "            self._load_checkpoint(resume)\n",
        "        for p in self.ema.parameters():\n",
        "            p.requires_grad_(False)\n",
        "\n",
        "    def _load_checkpoint(self, checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "        assert isinstance(checkpoint, dict)\n",
        "        if 'state_dict_ema' in checkpoint:\n",
        "            new_state_dict = OrderedDict()\n",
        "            for k, v in checkpoint['state_dict_ema'].items():\n",
        "                # ema model may have been wrapped by DataParallel, and need module prefix\n",
        "                if self.ema_has_module:\n",
        "                    name = 'module.' + k if not k.startswith('module') else k\n",
        "                else:\n",
        "                    name = k\n",
        "                new_state_dict[name] = v\n",
        "            self.ema.load_state_dict(new_state_dict)\n",
        "            _logger.info(\"Loaded state_dict_ema\")\n",
        "        else:\n",
        "            _logger.warning(\"Failed to find state_dict_ema, starting from loaded model weights\")\n",
        "\n",
        "    def update(self, model):\n",
        "        # correct a mismatch in state dict keys\n",
        "        needs_module = hasattr(model, 'module') and not self.ema_has_module\n",
        "        with torch.no_grad():\n",
        "            msd = model.state_dict()\n",
        "            for k, ema_v in self.ema.state_dict().items():\n",
        "                if needs_module:\n",
        "                    k = 'module.' + k\n",
        "                model_v = msd[k].detach()\n",
        "                if self.device:\n",
        "                    model_v = model_v.to(device=self.device)\n",
        "                ema_v.copy_(ema_v * self.decay + (1. - self.decay) * model_v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDgVpe8s6S-u"
      },
      "outputs": [],
      "source": [
        "class CustomTrainer:\n",
        "  def __init__(self, args, model, train_data, save_dir):\n",
        "    self.model = model\n",
        "\n",
        "    #self.model_ema = ModelEma(model, decay=0.9997)\n",
        "\n",
        "    self.save_dir = save_dir\n",
        "    if not os.path.exists(self.save_dir):\n",
        "      os.makedirs(self.save_dir)\n",
        "\n",
        "    self.log_path = f'{self.save_dir}/log.txt'\n",
        "\n",
        "    self.optimizer = AdamW(model.parameters(), lr = args.lr)\n",
        "\n",
        "    self.scaler = torch.cuda.amp.GradScaler() \n",
        "\n",
        "    total_steps = int(len(train_data) * args.epoch_n/(args.batch_size))\n",
        "    warmup_steps = int(total_steps * args.warmup_ratio)\n",
        "    print('total_steps: ', total_steps)\n",
        "    print('warmup_steps: ', warmup_steps)\n",
        "\n",
        "    self.scheduler = get_cosine_schedule_with_warmup(self.optimizer, \n",
        "                                                     num_warmup_steps = warmup_steps, \n",
        "                                                     num_training_steps = total_steps)\n",
        "    \n",
        "    self.loss_fn = nn.CrossEntropyLoss(label_smoothing = args.smoothing)\n",
        "    self.val_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    self.best_score = 0.0\n",
        "\n",
        "    self.log(f'trainer is ready')\n",
        "\n",
        "\n",
        "  def run(self, args, train_loader, val_loader):\n",
        "    for epoch in range(args.epoch_n):\n",
        "      gc.collect()\n",
        "      learning_rate = self.optimizer.param_groups[0]['lr']\n",
        "      print('learning_rate: ', learning_rate)\n",
        "      print(f'----- train, epoch{epoch + 1} -----')\n",
        "      train_loss, train_score = self.train_function(args, train_loader)\n",
        "      print(' ')\n",
        "      print(f'train_loss: {train_loss:.6f}, train_score: {train_score:.6f}')\n",
        "\n",
        "      self.log(f'learning_rate: {learning_rate}')\n",
        "      self.log(f'----- train, epoch{epoch + 1} -----') \n",
        "      self.log(' ')\n",
        "      self.log(f'train_loss: {train_loss:.6f}, train_score: {train_score:.6f}')\n",
        "      \n",
        "\n",
        "      print('----------------------------------')\n",
        "\n",
        "      print(f'----- val, epoch{epoch + 1} -----')\n",
        "      with torch.no_grad():\n",
        "        val_loss, val_score = self.val_function(args, val_loader)\n",
        "      print(' ')\n",
        "      print(f'val_loss: {val_loss:.6f}, val_score: {val_score:.6f}')\n",
        "\n",
        "      self.log(f'----- val, epoch{epoch+1} -----') \n",
        "      self.log(' ')\n",
        "      self.log(f'val_loss: {val_loss:.6f}, val_score: {val_score:.6f}')\n",
        "\n",
        "\n",
        "      if val_score >= self.best_score:\n",
        "        torch.save(self.model.state_dict(), self.save_dir + '/best-acc-epoch' + f'{epoch+1}'.zfill(3) + '.bin')#torch.save(self.model_ema.ema.state_dict(), self.save_dir + '/best-acc-epoch' + f'{epoch+1}'.zfill(3) + '.bin')\n",
        "        self.best_score = val_score\n",
        "        print(f'model is saved when epoch is : {epoch + 1}')\n",
        "        self.log(f'model is saved when epoch is : {epoch + 1}')\n",
        "\n",
        "      print('----------------------------------')\n",
        "      print(' ')\n",
        "      self.log('----------------------------------')\n",
        "      self.log(' ')\n",
        "\n",
        "\n",
        "  def train_function(self, args, train_loader):\n",
        "      self.model.train()\n",
        "\n",
        "      total_loss = 0.0\n",
        "      total_score = 0.0\n",
        "      for bi, data in enumerate(tqdm(train_loader)):\n",
        "        data = [x.to(args.device) for x in data]\n",
        "        video, label = data\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        #with torch.cuda.amp.autocast():\n",
        "        out = self.model(video)\n",
        "        loss = self.loss_fn(out, label.reshape(-1))\n",
        "        if loss.isnan():\n",
        "          break\n",
        "      \n",
        "        loss.backward()  \n",
        "        #torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        #self.scaler.scale(loss).backward()  \n",
        "        #self.scaler.step(self.optimizer) \n",
        "        #self.scaler.update()   \n",
        "\n",
        "        #self.model_ema.update(self.model)\n",
        "\n",
        "        self.scheduler.step()\n",
        "        \n",
        "\n",
        "        pred = out.argmax(1).cpu()\n",
        "        label = label.cpu().detach().numpy()\n",
        "        batch_acc = accuracy_score(label, pred)\n",
        "\n",
        "        total_loss += loss.detach().cpu()\n",
        "        total_score += batch_acc\n",
        "\n",
        "      return total_loss/len(train_loader), total_score/len(train_loader)\n",
        "\n",
        "  def val_function(self, args, val_loader):\n",
        "    self.model.eval()#self.model_ema.ema.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    preds, labels = [], []\n",
        "    for bi, data in enumerate(tqdm(val_loader)):\n",
        "      data = [x.to(args.device) for x in data]\n",
        "      video, label = data\n",
        "\n",
        "      out = self.model(video)#out = self.model_ema.ema(video)\n",
        "\n",
        "      loss = self.val_loss_fn(out, label.reshape(-1))\n",
        "\n",
        "      total_loss += loss.detach().cpu() \n",
        "\n",
        "      pred = out.argmax(1).detach().cpu().tolist()\n",
        "      label = label.reshape(-1).detach().cpu().tolist()\n",
        "\n",
        "      preds.extend(pred)\n",
        "      labels.extend(label)\n",
        "\n",
        "    total_score = accuracy_score(labels, preds)\n",
        "    return total_loss/len(val_loader), total_score\n",
        "\n",
        "  def log(self, message):\n",
        "    with open(self.log_path, 'a+') as logger:\n",
        "      logger.write(f'{message}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYHN0SNbBGSf"
      },
      "source": [
        "## run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfZOHK3M9Z7I"
      },
      "outputs": [],
      "source": [
        "# k-fold training\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  args = CustomConfig()\n",
        "  folds, df = preprocess(args)\n",
        "\n",
        "  for i in range(1, args.fold_n):\n",
        "    seed_everything(args)\n",
        "\n",
        "    args.smoothing = 0.75\n",
        "    args.max_frame = 100\n",
        "    args.epoch_n = 40\n",
        "    args.num_workers = 12\n",
        "\n",
        "    train_df, val_df = folds[i]\n",
        "\n",
        "    #train_df = train_df[train_df['ratio']>0.7].reset_index(drop = True)\n",
        "    #val_df = val_df[val_df['ratio']>0.7].reset_index(drop = True)\n",
        "\n",
        "    train_dataset = CustomDataset(args, train_df, data)\n",
        "    val_dataset = CustomDataset(args, val_df, data, 'noaug')\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = args.batch_size, num_workers = args.num_workers, shuffle = True, drop_last = True)\n",
        "    test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = args.batch_size, num_workers = args.num_workers, shuffle = False, drop_last = False)\n",
        "\n",
        "    model = CustomModel(args)\n",
        "    model = model.to(args.device)\n",
        "     \n",
        "    save_dir = f'/content/drive/MyDrive/Kaggle/model/robertaprelm-ls0.75-feature-ldist-divide-head-gru/fold{i + 1}'\n",
        "\n",
        "    trainer = CustomTrainer(args, model, train_df, save_dir)\n",
        "    result = trainer.run(args, train_dataloader, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVgxv9LLcDOg"
      },
      "source": [
        "## inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df5CrasfcFb6"
      },
      "outputs": [],
      "source": [
        "# inference test setting\n",
        "\n",
        "model = CustomModel(args)\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Kaggle/model/main/robertaprelm-ls0.75-feature-ldist-divide-head/fold2/best-acc-epoch034.bin', map_location = 'cpu')\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()\n",
        "pass\n",
        "\n",
        "label_index = read_dict(args, f\"/content/drive/MyDrive/Kaggle/sign_to_prediction_index_map.json\")\n",
        "index_label = dict([(label_index[key], key) for key in label_index])\n",
        "train_df, val_df = folds[1]\n",
        "dataset = CustomDataset(args, val_df, data, 'aug')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_9igiiycNY-",
        "outputId": "92d53b38-e5c1-43b9-b489-cf66b0cf6289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "true:  pretty\n",
            "pred:  pretty\n"
          ]
        }
      ],
      "source": [
        "# for multiple run\n",
        "\n",
        "train_df, val_df = folds[1]\n",
        "dataset = CustomDataset(args, val_df, data, 'aug')\n",
        "i = random.randint(0, len(val_df)-1)\n",
        "sample = dataset[i]\n",
        "\n",
        "print('true: ', index_label[sample[-1].tolist()])\n",
        "print('pred: ', index_label[model(sample[0].unsqueeze(0)).argmax(1)[0].tolist()])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Y5UmPWijX00m",
        "9RhpY53mg9WH",
        "zdfa3g-qgzVw",
        "nDd3XDD3g2L_",
        "4PJvFRJvhkeV",
        "-Ged5z_rhlbl",
        "uaGqMd6XkiRD",
        "Wui0LgnpBE3A",
        "PYHN0SNbBGSf",
        "CVgxv9LLcDOg"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}